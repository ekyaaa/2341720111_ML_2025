{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tugas\n",
        "\n",
        "    1. Lakukan percobaan penggunaan ANNOY, FAISS, dan HNSWLIB pada dataset sekunder berukuran besar (Micro Spotify) pada link berikut: https://www.kaggle.com/datasets/bwandowando/spotify-songs-with-attributes-and-lyrics/data\n",
        "    2. Download data dan load CSV filenya (pilih dataset yang pertama dari dua dataset)\n",
        "    3. Pilih hanya fitur numerik saja, dan lakukan normalisasi menggunakan StandardScaler\n",
        "    4. Lakukan pencarian track terdekat dan bandingkan hasilnya\n",
        "\n"
      ],
      "metadata": {
        "id": "7izh5TSKlW0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install annoy faiss-cpu hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71pJNtdUl4h8",
        "outputId": "09bd1155-d5d3-4d61-f10e-e33b1cb69165"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/647.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m614.4/647.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: annoy, hnswlib\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp312-cp312-linux_x86_64.whl size=551809 sha256=33f0aa8b7c24138765dc47f238a0a481c39b00d0b5e9067661e74a73ca2e57e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/b9/53/a3b2d1fe1743abadddec6aa541294b24fdbc39d7800bc57311\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp312-cp312-linux_x86_64.whl size=2528143 sha256=0beb888cd806ef332341b817892347689c2c17c2483dbf9ebbdc4e4e7e89e260\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/39/b3/cbd7f9cbb76501d2d5fbc84956e70d0b94e788aac87bda465e\n",
            "Successfully built annoy hnswlib\n",
            "Installing collected packages: annoy, hnswlib, faiss-cpu\n",
            "Successfully installed annoy-1.17.3 faiss-cpu-1.13.0 hnswlib-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdLQ7r3Gk0kE",
        "outputId": "210bcf53-910c-4fac-feb8-e4d6a0c8a2b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/bwandowando/spotify-songs-with-attributes-and-lyrics?dataset_version_number=19...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 894M/894M [00:09<00:00, 101MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Exact] Waktu: 4623.783 s\n",
            "[Annoy] Waktu: 145.218 s\n",
            "[HNSW] Waktu: 366.529 s\n",
            "[FAISS] Waktu: 836.581 s\n",
            "\n",
            "Recall@k (semakin tinggi semakin akurat):\n",
            "Annoy : 0.9486\n",
            "HNSW  : 0.9955\n",
            "FAISS : 0.9982\n",
            "\n",
            "Tetangga terdekat (item pertama):\n",
            "Exact : [     0 394553 764272 837727 749223]\n",
            "Annoy : [0, 394553, 764272, 837727, 749223]\n",
            "HNSW  : [     0 394553 764272 837727 749223]\n",
            "FAISS : [     0 394553 764272 837727 749223]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "import faiss\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Utility: Benchmark Wrapper\n",
        "# ---------------------------------------------------------\n",
        "def timer(fn, *args, **kwargs):\n",
        "    t0 = time.time()\n",
        "    output = fn(*args, **kwargs)\n",
        "    return output, time.time() - t0\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Load Dataset\n",
        "# ---------------------------------------------------------\n",
        "print(\"Downloading dataset...\")\n",
        "dataset_path = kagglehub.dataset_download(\n",
        "    \"bwandowando/spotify-songs-with-attributes-and-lyrics\"\n",
        ")\n",
        "\n",
        "csv_path = dataset_path + \"/songs_with_attributes_and_lyrics.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "numeric_cols = [\n",
        "    \"danceability\", \"energy\", \"loudness\", \"speechiness\",\n",
        "    \"acousticness\", \"instrumentalness\", \"liveness\",\n",
        "    \"valence\", \"tempo\"\n",
        "]\n",
        "\n",
        "X = df[numeric_cols].values.astype(\"float32\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Preprocessing\n",
        "# ---------------------------------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_norm = scaler.fit_transform(X).astype(\"float32\")\n",
        "\n",
        "k = 10  # jumlah tetangga\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. Exact Nearest Neighbor (Brute Force)\n",
        "# ---------------------------------------------------------\n",
        "def exact_knn(data, k):\n",
        "    model = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric=\"euclidean\")\n",
        "    model.fit(data)\n",
        "    dist, idx = model.kneighbors(data)\n",
        "    return dist, idx\n",
        "\n",
        "\n",
        "(exact_res, exact_idx), t_exact = timer(exact_knn, X_norm, k)\n",
        "print(f\"[Exact] Waktu: {t_exact:.3f} s\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. Annoy\n",
        "# ---------------------------------------------------------\n",
        "def annoy_knn(data, k, n_trees=20):\n",
        "    dim = data.shape[1]\n",
        "    index = AnnoyIndex(dim, metric=\"euclidean\")\n",
        "\n",
        "    for i, vec in enumerate(data):\n",
        "        index.add_item(i, vec)\n",
        "    index.build(n_trees)\n",
        "\n",
        "    neighbors = [index.get_nns_by_vector(vec, k) for vec in data]\n",
        "    return neighbors\n",
        "\n",
        "\n",
        "annoy_idx, t_ann = timer(annoy_knn, X_norm, k)\n",
        "print(f\"[Annoy] Waktu: {t_ann:.3f} s\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. HNSWLIB\n",
        "# ---------------------------------------------------------\n",
        "def hnsw_knn(data, k, ef=200, M=16):\n",
        "    dim = data.shape[1]\n",
        "    hnsw = hnswlib.Index(space=\"l2\", dim=dim)\n",
        "    hnsw.init_index(max_elements=len(data), ef_construction=ef, M=M)\n",
        "\n",
        "    hnsw.add_items(data)\n",
        "    hnsw.set_ef(ef)\n",
        "\n",
        "    labels, dist = hnsw.knn_query(data, k)\n",
        "    return labels\n",
        "\n",
        "\n",
        "(hnsw_idx), t_hnsw = timer(hnsw_knn, X_norm, k)\n",
        "print(f\"[HNSW] Waktu: {t_hnsw:.3f} s\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. FAISS IVF-Flat\n",
        "# ---------------------------------------------------------\n",
        "def faiss_knn(data, k, nlist=100, nprobe=10):\n",
        "    dim = data.shape[1]\n",
        "\n",
        "    quantizer = faiss.IndexFlatL2(dim)\n",
        "    index = faiss.IndexIVFFlat(quantizer, dim, nlist)\n",
        "    index.train(data)\n",
        "    index.add(data)\n",
        "    index.nprobe = nprobe\n",
        "\n",
        "    dist, idx = index.search(data, k)\n",
        "    return idx\n",
        "\n",
        "\n",
        "faiss_idx, t_faiss = timer(faiss_knn, X_norm, k)\n",
        "print(f\"[FAISS] Waktu: {t_faiss:.3f} s\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Optional: hitung tingkat keakuratan Approx vs Exact\n",
        "# ---------------------------------------------------------\n",
        "def recall_at_k(true_idx, approx_idx):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(len(true_idx)):\n",
        "        gold = set(true_idx[i])\n",
        "        pred = set(approx_idx[i])\n",
        "        correct += len(gold.intersection(pred))\n",
        "        total += len(gold)\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "rec_annoy = recall_at_k(exact_idx, annoy_idx)\n",
        "rec_hnsw = recall_at_k(exact_idx, hnsw_idx)\n",
        "rec_faiss = recall_at_k(exact_idx, faiss_idx)\n",
        "\n",
        "print(\"\\nRecall@k (semakin tinggi semakin akurat):\")\n",
        "print(f\"Annoy : {rec_annoy:.4f}\")\n",
        "print(f\"HNSW  : {rec_hnsw:.4f}\")\n",
        "print(f\"FAISS : {rec_faiss:.4f}\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Tampilkan Contoh Neighbor\n",
        "# ---------------------------------------------------------\n",
        "item = 0  # track pertama\n",
        "\n",
        "print(\"\\nTetangga terdekat (item pertama):\")\n",
        "print(\"Exact :\", exact_idx[item][:5])\n",
        "print(\"Annoy :\", annoy_idx[item][:5])\n",
        "print(\"HNSW  :\", hnsw_idx[item][:5])\n",
        "print(\"FAISS :\", faiss_idx[item][:5])\n"
      ]
    }
  ]
}